from discord.ext import commands
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import os

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel("gemini-1.5-flash")

@commands.command()
async def mcp(ctx, *, query: str):
    await ctx.send(f"ğŸ§  MCP å•Ÿå‹•ä¸­ï¼Œç›®æ¨™ï¼š{query}")
    try:
        # Step 1: Gemini è½‰æœå°‹é—œéµå­—
        search_prompt = f"è«‹å°‡é€™å¥è©±è½‰æˆæœå°‹å¼•æ“ç”¨çš„ç²¾ç°¡é—œéµå­—ï¼š'{query}'"
        search_term = model.generate_content(search_prompt).text.strip()
        await ctx.send(f"ğŸ” æœå°‹ä¸­ï¼š{search_term}")

        # Step 2: DuckDuckGo æœå°‹
        url = f"https://html.duckduckgo.com/html/?q={search_term}"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        result_link = soup.find("a", class_="result__a")

        if not result_link:
            await ctx.send("âš ï¸ æ‰¾ä¸åˆ°ä»»ä½•æœå°‹çµæœã€‚")
            return

        raw_url = result_link['href']
        target_url = "https:" + raw_url if raw_url.startswith("//") else raw_url
        await ctx.send(f"ğŸ”— ä½¿ç”¨è³‡æ–™ä¾†æºï¼š{target_url}")

        # Step 3: æ“·å–å¤šç¨®å¸¸è¦‹æ¨™ç±¤æ–‡å­—ï¼ˆå¢åŠ å‘½ä¸­ç‡ï¼‰
        content_res = requests.get(target_url, headers=headers, timeout=10)
        content_soup = BeautifulSoup(content_res.text, "html.parser")
        paragraphs = content_soup.find_all(["p", "article", "section", "div"])
        texts = [p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 50]
        all_text = " ".join(texts)

        if len(all_text) < 200:
            await ctx.send("âš ï¸ æŠ“åˆ°çš„è³‡æ–™å¯èƒ½ä¸è¶³ï¼ŒAI ä»å°‡å˜—è©¦è£œå…¨ã€‚")
            all_text += "\nï¼ˆé€™äº›è³‡æ–™è¼ƒå°‘ï¼Œè«‹æ ¹æ“šä½ éå»çš„çŸ¥è­˜é€²è¡Œæ¨è«–èˆ‡è£œå……ï¼‰"

        if len(all_text) > 12000:
            all_text = all_text[:12000]
            await ctx.send("âš ï¸ æ–‡ç« éé•·ï¼Œå·²æˆªå–å‰ 12000 å­—ã€‚")

        # Step 4: AI åˆ†æèˆ‡æ‘˜è¦
        prompt = (
            "ä»¥ä¸‹æ˜¯ä¸€ç¯‡æ–‡ç« çš„æ®µè½å…§å®¹ï¼Œè«‹ä½ å¹«æˆ‘ç”¨ä¸­æ–‡æ‘˜è¦é‡é»ã€èªªæ˜ä¸»é¡Œï¼Œ"
            "å¦‚æœæœ‰éœ€è¦å¯ä»¥è£œå……æ¨è«–æˆ–å¹«æˆ‘ç¿»è­¯è‰±æ¾€éƒ¨åˆ†ï¼š\n" + all_text
        )
        summary = model.generate_content(prompt).text.strip()

        # åˆ†æ®µè¼¸å‡º
        chunks = [summary[i:i+1800] for i in range(0, len(summary), 1800)]
        for chunk in chunks:
            await ctx.send(chunk)

    except Exception as e:
        await ctx.send(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
